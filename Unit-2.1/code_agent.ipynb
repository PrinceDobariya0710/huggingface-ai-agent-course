{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv==1.0.1 \n",
    "!pip install google-auth smolagents[litellm] \n",
    "!pip install llama-index-tools-google llama-index-llms-gemini llama-index-embeddings-gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below code if you are using notebook in local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import LiteLLMModel\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Replace all calls to HfApiModel\n",
    "llm_model = LiteLLMModel(\n",
    "    model_id=\"gemini/gemini-2.0-flash\", # you can see other model names here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models. It is important to prefix the name with \"gemini/\"\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    max_tokens=8192\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below code if you are using notebook in Google Collabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import LiteLLMModel\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "# Replace all calls to HfApiModel\n",
    "llm_model = LiteLLMModel(\n",
    "    model_id=\"gemini/gemini-2.0-flash\", # you can see other model names here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models. It is important to prefix the name with \"gemini/\"\n",
    "    api_key=userdata.get('GEMINI_API_KEY'),\n",
    "    max_tokens=8192\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel\n",
    "\n",
    "agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=llm_model)\n",
    "\n",
    "agent.run(\"Search for the best music recommendations for a party at the Wayne's mansion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, tool\n",
    "\n",
    "@tool\n",
    "def suggest_menu(occasion: str) -> str:\n",
    "    \"\"\"\n",
    "    Suggests a menu based on the occasion.\n",
    "    Args:\n",
    "        occasion (str): The type of occasion for the party. Allowed values are:\n",
    "                        - \"casual\": Menu for casual party.\n",
    "                        - \"formal\": Menu for formal party.\n",
    "                        - \"superhero\": Menu for superhero party.\n",
    "                        - \"custom\": Custom menu.\n",
    "    \"\"\"\n",
    "    if occasion == \"casual\":\n",
    "        return \"Pizza, snacks, and drinks.\"\n",
    "    elif occasion == \"formal\":\n",
    "        return \"3-course dinner with wine and dessert.\"\n",
    "    elif occasion == \"superhero\":\n",
    "        return \"Buffet with high-energy and healthy food.\"\n",
    "    else:\n",
    "        return \"Custom menu for the butler.\"\n",
    "\n",
    "agent = CodeAgent(tools=[suggest_menu], model=llm_model)\n",
    "\n",
    "agent.run(\"Prepare a formal menu for the party.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, HfApiModel\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "agent = CodeAgent(tools=[], model=llm_model, additional_authorized_imports=['datetime'])\n",
    "\n",
    "agent.run(\n",
    "    \"\"\"\n",
    "    Alfred needs to prepare for the party. Here are the tasks:\n",
    "    1. Prepare the drinks - 30 minutes\n",
    "    2. Decorate the mansion - 60 minutes\n",
    "    3. Set up the menu - 45 minutes\n",
    "    3. Prepare the music and playlist - 45 minutes\n",
    "\n",
    "    If we start right now, at what time will the party be ready?\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel, VisitWebpageTool, FinalAnswerTool, Tool, tool\n",
    "\n",
    "@tool\n",
    "def suggest_menu(occasion: str) -> str:\n",
    "    \"\"\"\n",
    "    Suggests a menu based on the occasion.\n",
    "    Args:\n",
    "        occasion: The type of occasion for the party.\n",
    "    \"\"\"\n",
    "    if occasion == \"casual\":\n",
    "        return \"Pizza, snacks, and drinks.\"\n",
    "    elif occasion == \"formal\":\n",
    "        return \"3-course dinner with wine and dessert.\"\n",
    "    elif occasion == \"superhero\":\n",
    "        return \"Buffet with high-energy and healthy food.\"\n",
    "    else:\n",
    "        return \"Custom menu for the butler.\"\n",
    "\n",
    "@tool\n",
    "def catering_service_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    This tool returns the highest-rated catering service in Gotham City.\n",
    "\n",
    "    Args:\n",
    "        query: A search term for finding catering services.\n",
    "    \"\"\"\n",
    "    # Example list of catering services and their ratings\n",
    "    services = {\n",
    "        \"Gotham Catering Co.\": 4.9,\n",
    "        \"Wayne Manor Catering\": 4.8,\n",
    "        \"Gotham City Events\": 4.7,\n",
    "    }\n",
    "\n",
    "    # Find the highest rated catering service (simulating search query filtering)\n",
    "    best_service = max(services, key=services.get)\n",
    "\n",
    "    return best_service\n",
    "\n",
    "class SuperheroPartyThemeTool(Tool):\n",
    "    name = \"superhero_party_theme_generator\"\n",
    "    description = \"\"\"\n",
    "    This tool suggests creative superhero-themed party ideas based on a category.\n",
    "    It returns a unique party theme idea.\"\"\"\n",
    "\n",
    "    inputs = {\n",
    "        \"category\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The type of superhero party (e.g., 'classic heroes', 'villain masquerade', 'futuristic gotham').\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def forward(self, category: str):\n",
    "        themes = {\n",
    "            \"classic heroes\": \"Justice League Gala: Guests come dressed as their favorite DC heroes with themed cocktails like 'The Kryptonite Punch'.\",\n",
    "            \"villain masquerade\": \"Gotham Rogues' Ball: A mysterious masquerade where guests dress as classic Batman villains.\",\n",
    "            \"futuristic gotham\": \"Neo-Gotham Night: A cyberpunk-style party inspired by Batman Beyond, with neon decorations and futuristic gadgets.\"\n",
    "        }\n",
    "\n",
    "        return themes.get(category.lower(), \"Themed party idea not found. Try 'classic heroes', 'villain masquerade', or 'futuristic gotham'.\")\n",
    "\n",
    "\n",
    "# Alfred, the butler, preparing the menu for the party\n",
    "agent = CodeAgent(\n",
    "    tools=[\n",
    "        DuckDuckGoSearchTool(),\n",
    "        VisitWebpageTool(),\n",
    "        suggest_menu,\n",
    "        catering_service_tool,\n",
    "        SuperheroPartyThemeTool()\n",
    "        ],\n",
    "    model=llm_model,\n",
    "    max_steps=10,\n",
    "    verbosity_level=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Give me best playlist for a party at the Wayne's mansion. The party idea is a 'villain masquerade' theme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"<enter here your huggingface username>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below code if you are running code in local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    agent.push_to_hub(f'{username}/AlfredAgentBy{username}', token=os.getenv('HF_TOKEN'))\n",
    "except Exception as e:\n",
    "    print(\"Error pushing to hub:\", str(e))\n",
    "    print(\"\\nTroubleshooting steps:\")\n",
    "    print(\"1. Verify your HF_TOKEN has write access in your Hugging Face account settings\")\n",
    "    print(\"2. Check if the repository name is available and you have permissions\")\n",
    "    print(\"3. Try creating the repository manually on huggingface.co first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below code if you are using Google Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "try:\n",
    "    agent.push_to_hub(f'{username}/AlfredAgentBy{username}', token=userdata.get('HF_TOKEN'))\n",
    "except Exception as e:\n",
    "    print(\"Error pushing to hub:\", str(e))\n",
    "    print(\"\\nTroubleshooting steps:\")\n",
    "    print(\"1. Verify your HF_TOKEN has write access in your Hugging Face account settings\")\n",
    "    print(\"2. Check if the repository name is available and you have permissions\")\n",
    "    print(\"3. Try creating the repository manually on huggingface.co first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install smolagents[telemetry] opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-smolagents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below code if you are using Google Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from google.colab import userdata\n",
    "LANGFUSE_PUBLIC_KEY=userdata.get(\"LANGFUSE_PUBLIC_KEY\")\n",
    "LANGFUSE_SECRET_KEY=userdata.get(\"LANGFUSE_SECRET_KEY\")\n",
    "LANGFUSE_AUTH=base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
    "\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://cloud.langfuse.com/api/public/otel\" # EU data region\n",
    "# os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://us.cloud.langfuse.com/api/public/otel\" # US data region\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below code if you are running code in local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "\n",
    "LANGFUSE_PUBLIC_KEY=os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "LANGFUSE_SECRET_KEY=os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "LANGFUSE_AUTH=base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
    "\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://cloud.langfuse.com/api/public/otel\" # EU data region\n",
    "# os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = \"https://us.cloud.langfuse.com/api/public/otel\" # US data region\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "\n",
    "from openinference.instrumentation.smolagents import SmolagentsInstrumentor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "trace_provider = TracerProvider()\n",
    "trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))\n",
    "\n",
    "SmolagentsInstrumentor().instrument(tracer_provider=trace_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent.run(\"Give me best playlist for a party at the Wayne's mansion. The party idea is a 'villain masquerade' theme\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
